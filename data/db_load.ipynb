{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Loading Tool\n",
    "This notebook lets you insert data sets into the local Supabase db from the source PKL files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the PKL files for all sources\n",
    "food_network = pd.read_pickle('cleaned_food_network_restaurants_with_validated_addresses.pkl.zst', compression='zstd')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update typo in show name\n",
    "\n",
    "food_network.loc[food_network['show'] == 'Diners, Dive-Ins, and Dives', 'show'] = 'Diners, Drive-Ins, and Dives'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "We must take the input files and destructure them into normalized entities so that we may populate our DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Shows\n",
    "\n",
    "food_network_show_names = food_network['show'].unique()\n",
    "# Make them into their own dataframe\n",
    "shows = pd.DataFrame(food_network_show_names, columns=['name'])\n",
    "# Add the platform  and publisher names as a columns\n",
    "shows['publisher'] = 'Food Network'\n",
    "shows['platform'] = 'Television'\n",
    "shows.drop_duplicates(subset=['name'], inplace=True)\n",
    "\n",
    "# Dedupe\n",
    "food_network.drop_duplicates(subset=['show', 'restaurant', 'validated_address'], inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "food_network = food_network[['show', 'restaurant', 'description', 'rating', 'phone',  'website', 'website status', 'validated_address', 'city', 'state', 'zip']]\n",
    "# Rename columns\n",
    "food_network.columns = ['show', 'name', 'description', 'rating', 'phone', 'website', 'website_status', 'address', 'city', 'state', 'zip']\n",
    "\n",
    "# Extract Restaurants\n",
    "food_network_restaurants = food_network[['name', 'description', 'rating', 'phone',  'website', 'website_status', 'address', 'city', 'state', 'zip']]\n",
    "# Dedupe restaurants that may have been on multiple shows\n",
    "food_network_restaurants = food_network_restaurants.drop_duplicates(subset=['name', 'address'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import config\n",
    "\n",
    "# Prod Variant:\n",
    "engine = create_engine(f'postgresql://{config.PROD_DB_USER}:{config.PROD_DB_PASSWORD}@{config.PROD_DB_HOST}:{config.PROD_DB_PORT}/{config.PROD_DB_NAME}?gssencmode=disable')\n",
    "\n",
    "# Local Variant:\n",
    "# engine = create_engine(f'postgresql://{config.LOCAL_DB_USER}:{config.LOCAL_DB_PASSWORD}@{config.LOCAL_DB_HOST}:{config.LOCAL_DB_PORT}/{config.LOCAL_DB_NAME}')\n",
    "\n",
    "# Clear out tables for new data\n",
    "response = input(\"This will delete all records in the database shows, restaurants, and shows_restaurants tables. Enter 'yes' to continue: \")\n",
    "if response == \"yes\":\n",
    "  with engine.connect() as connection:\n",
    "    connection.execute(text(\"TRUNCATE TABLE shows RESTART IDENTITY CASCADE\"))\n",
    "    connection.execute(text(\"TRUNCATE TABLE restaurants RESTART IDENTITY CASCADE\"))\n",
    "    connection.execute(text(\"TRUNCATE TABLE shows_restaurants RESTART IDENTITY CASCADE\"))\n",
    "    connection.commit()\n",
    "\n",
    "# Write to the database\n",
    "shows.to_sql('shows', engine, if_exists='append', index=False)\n",
    "food_network_restaurants.to_sql('restaurants', engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now read from the database the data we just inserted because the database has assigned them IDs and we must use those same IDs to produce the shows_restaurants join table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read from the database to get the IDs of shows and restaurants\n",
    "db_shows = pd.read_sql('SELECT * FROM shows', engine)\n",
    "db_restaurants = pd.read_sql('SELECT * FROM restaurants', engine)\n",
    "\n",
    "\n",
    "# Create empty dataframe with two columns for matched IDs\n",
    "shows_restaurants = pd.DataFrame(columns=['show_id', 'restaurant_id'])\n",
    "\n",
    "# Match the restaurant to the show based on their ids\n",
    "for index, row in food_network.iterrows():\n",
    "  show_id = db_shows[db_shows['name'] == row['show']].iloc[0]['id']\n",
    "  restaurant_id = db_restaurants[(db_restaurants['name'] == row['name']) & (db_restaurants['address'] == row['address'])].iloc[0]['id']\n",
    "  shows_restaurants = shows_restaurants._append({'show_id': show_id, 'restaurant_id': restaurant_id}, ignore_index=True)\n",
    "\n",
    "# Write to join table in DB\n",
    "shows_restaurants.to_sql('shows_restaurants', engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tv-eats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
